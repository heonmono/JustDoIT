{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 👊 CHAPTER 14 순환 신경망 (RNN, Recurrent Neural Network)- (1)\n",
    "\n",
    "\n",
    "#### 🙋 Chapter Manager : 남창헌  🙎 Contents Add : 권태양                          \n",
    "\n",
    "저번 포스팅인 [06. 합성곱 신경망 - CNN](http://excelsior-cjh.tistory.com/180)에서는 이미지 데이터에 적합한 모델인 CNN에 대해 알아보았다. 이번 포스팅에서는 아래의 그림과 같이 자연어(NL, Natural Language)나 음성신호, 주식과 같은 연속적인(sequential) **시계열**(time series) 데이터에 적합한 모델인 **RNN**(Recurrent Neural Network)에 대해 알아보도록 하자.\n",
    "\n",
    "**RNN**의 가장 큰 특징은 기존 **CNN**은 고정된 입력데이터와 출력값을 가지는 반면, RNN은 **임의의 길이**를 가진 **Sequence**한 데이터에 유용하며 이는, 입력과 출력이 가변적일 수 있는것을 의미한다. \n",
    "\n",
    "두번째로, RNN은 이전 학습들이 다음 학습들에 영향을 주므로, 순서를 가지고 있는 데이터에 유용하다. 이에 따라 사용되는 종류로, 기계번역과 비디오, 음악, 주가 등 순서를 가지는(이전의 내용이 다음 내용에 영향을 주는) 데이터 분석에 쓰이며, 이는 다양하고 창의적인 활동이 가능하게 만들어준다.\n",
    "![](./images/sequence_data.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 👊14.1. 순환 뉴런(Recurrent Neurons)\n",
    "[이전 포스팅](http://excelsior-cjh.tistory.com/category/DeepLearning/%EA%B0%9C%EB%85%90)에서 살펴본 신경망은 입력층 → 출력층 한 방향으로만 흐르는 피드포워드(feedforward) 신경망이었다.  RNN(순환 신경망)은 피드포워드 신경망과 비슷하지만, 아래의 그림과 같이 출력이 다시 입력으로 받는 부분이 있다. \n",
    "\n",
    "![](./images/rnn01.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN은 입력($\\mathbf{x}$)을 받아 출력($\\mathbf{y}$)를 만들고, 이 출력을 다시 입력으로 받는다.  일반적으로 RNN을 그림으로 나타낼 때는 위의 그림처럼 하나로 나타내지 않고, 아래의 그림처럼 각 **타임 스텝**(time step) $t$ 마다 **순환 뉴런**을 펼쳐서 타임스텝 별 입력($x_t$)과 출력($y_t$)을 나타낸다. \n",
    "\n",
    "\n",
    "\n",
    "![](./images/rnn02.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 👊14.2 메모리 셀(Memory Cell)\n",
    "\n",
    "타임 스텝 $t$ 에서 순환 뉴런의 출력은 이전 타임 스텝의 모든 입력에 대한 함수이기 때문에 이것을 **메모리**라고 볼 수 있다. 이렇게 타임 스텝에 걸쳐 어떠한 상태를 보존하는 신경망의 구성 요소를 **메모리 셀**(memory cell)이라고 한다. 일반적으로 타임 스텝 $t$ 에서 셀의 상태 $\\mathbf{h}_{t}$ (h = hidden)는 아래의 식과 같이 타임 스텝에서의 입력과 이전 타임 스텝의 상태에 대한 함수이다.  \n",
    "$$\n",
    "\\mathbf{h}_{t} = f \\left( \\mathbf{h}_{t-1}, \\mathbf{x}_{t} \\right)\n",
    "$$\n",
    "\n",
    "\n",
    "위에서 살펴본 RNN은 출력 $\\mathbf{y}_{t}$ 가 다시 입력으로 들어갔지만, 아래의 그림과 같이 일반적으로 많이 사용되는 RNN은 출력 $\\mathbf{y}_{t}$ 와 히든 상태(state) $\\mathbf{h}_{t}$가 구분되며, 입력으로는 $\\mathbf{h}_{t}$가 들어간다. RNN에서의 활성화 함수로는 $\\tanh$가 주로 사용되는데, 그 이유는 LSTM을 살펴볼 때 알아보도록 하자.\n",
    "\n",
    "\n",
    "\n",
    "![rnn](./images/rnn04.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 그림을 식으로 나타내면 다음과 같다.\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\mathbf{h}_{t} &= \\tanh \\left( \\mathbf{X}_{t} \\cdot \\mathbf{W}_{x} + \\mathbf{h}_{t-1} \\cdot \\mathbf{W}_{h} + \\mathbf{b} \\right) \\\\ &= \\tanh \\left( \\begin{bmatrix} \\mathbf{X}_{t} & \\mathbf{h}_{t-1} \\end{bmatrix}\\begin{bmatrix} \\mathbf{W}_{x} \\\\ \\mathbf{W}_{h} \\end{bmatrix} + \\mathbf{b} \\right) \\\\ \\mathbf{Y}_{t} &= \\mathbf{W}_{y}^{T} \\cdot \\mathbf{h}_{t}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "이러한 **memory cell, hidden state**는 이전 times의 결과가 현재 times의 학습에 영향을 준다. 이러한 특성이 **RNN**이 순서를 기억하는데 영향을 준다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이에 대하여는 ratsgo's blog에 rnn posting에 있는 그림을 보는 것이 이해하는데 수월하다.\n",
    "![](./images/latsgo.png)\n",
    "rnn이 기존과 다른 점은 이전 Hidden state에 대한 **Wh**와 \n",
    "데이터 x에 대한 **Wx** 그리고 output을 위한 **Wy**가 다 다르다는 점이다.\n",
    "많은 코드들에서 이에 대한 모양을 알아서 잡아주지만 이에 대해 이해하는 것이\n",
    "조금 더 low한 프로그래밍을 하고 데이터를 이해하는데 도움이 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그렇다면 각 파라미터의 사이즈를 파악해보자.\n",
    "\n",
    "- $\\mathbf{Y}_{t}$ : 타임 스텝 $t$에서 미니배치에 있는 각 샘플(미니배치)에 대한 순환 층의 출력이며, $m \\times n_{\\text{neurons}}$ 행렬($m$은 미니배치, $n_{\\text{neurons}}$은 뉴런 수)\n",
    "- $\\mathbf{X}_{t}$ : 모든 샘플의 입력값을 담고 있는 $m \\times n_{\\text{inputs}}$ 행렬 ($n_{\\text{inputs}}$은 입력 특성 수)\n",
    "- $\\mathbf{h}_{t}$ : 이전 샘플의 hidden state값을 담고 있는 $1 \\times n_{\\text{neurons}}$ 행렬 ($n_{\\text{neurons}}$은 뉴런수 )\n",
    "\n",
    "- $\\mathbf{W}_{xh}$ : 현재 타임 스텝 $t$의 입력에 대한 가중치를 담고 있는 $n_{\\text{inputs}} \\times n_{\\text{neurons}}$ 행렬\n",
    "- $\\mathbf{W}_{hh}$ : 현재 타임 스텝 $t$의 hidden state에 대한 가중치를 담고 있는 $n_{\\text{neurons}} \\times n_{\\text{neurons}}$ 행렬\n",
    "- $\\mathbf{W}_{hy}$  : 현재 타임 스텝 $t$ 의 출력에 대한 가중치를 담고 있는 $n_{\\text{neurons}} \\times n_{\\text{outputs}}$  행렬\n",
    "- $\\mathbf{b}$ : 각 뉴런의 편향(bias)을 담고 있는 $n_{\\text{neurons}}$ 크기의 벡터\n",
    "\n",
    "보기 불편하지만 이에 대한 이해가 필요하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 👊14.3 입력과 출력 시퀀스\n",
    "\n",
    "RNN은 아래의 그림(출처: [cs231n](http://cs231n.stanford.edu/2017/syllabus.html))과 같이 다양한 입력 시퀀스(sequence)를 받아 출력 시퀀스를 만들 수 있다. \n",
    "\n",
    "\n",
    "\n",
    "![rnn](./images/rnn05.png)\n",
    "\n",
    "\n",
    "\n",
    "위의 그림에서 Vector-to-Sequence는 첫 번째 타임 스텝에서 하나의 입력만(다른 모든 타임 스텝에서는 0)을 입력받아 시퀀스를 출력하는 네트워크이며, 이러한 모델은 Image Captioning에 사용할 수 있다. Sequence-to-Vector는 Vector-to-Sequence와는 반대로 입력으로 시퀀스를 받아 하나의 벡터를 출력하는 네트워크로, Sentiment Classification에 사용할 수 있다.  \n",
    "\n",
    "위의 그림의 오른쪽에서 세 번째 Sequence-to-Sequence 는 시퀀스를 입력받아 시퀀스를 출력하는 네트워크이며, 주식가격과 같은 시계열 데이터를 예측하는 데 사용할 수 있다.  마지막으로 Delayed Sequence-to-Sequence 는 **인코더**(encoder)에는 seq-to-vec 네트워크를 **디코더**(decoder)에는 vec-to-seq 네트워크를 연결한 것으로, 기계 번역에 사용된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 👊14.2 텐서플로로 기본 RNN 구성하기\n",
    "\n",
    "위에서 살펴본 RNN을 텐서플로(TensorFlow)를 이용해 구현해보도록 하자. 먼저, RNN의 구조를 살펴보기 위해 텐서플로에서 제공하는 RNN을 사용하지 않고, 간단한 RNN 모델을 구현해 보도록 하자.\n",
    "\n",
    "아래의 코드는 $\\tanh$ 를 활성화 함수로 사용하고, 5개의 뉴런으로 구성된 RNN을 구현 하였으며, 타임 스텝마다 크기 3의 입력을 받고 두개의 타임 스텝($t=0, t=1$)에 대해 작동한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# 일관된 출력을 위해 유사난수 초기화\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "sn.set()\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "# 한글출력\n",
    "# matplotlib.rc('font', family='AppleGothic')  # MacOS\n",
    "matplotlib.rc('font', family='Malgun Gothic')  # Windows\n",
    "plt.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y0_val:(4, 5)\n",
      "[[-0.0664006   0.9625767   0.68105793  0.7091854  -0.898216  ]\n",
      " [ 0.9977755  -0.71978897 -0.9965761   0.9673924  -0.9998972 ]\n",
      " [ 0.99999774 -0.99898803 -0.9999989   0.9967762  -0.9999999 ]\n",
      " [ 1.         -1.         -1.         -0.99818915  0.9995087 ]]\n",
      "Y1_val:(4, 5)\n",
      "[[ 1.         -1.         -1.          0.40200275 -0.9999998 ]\n",
      " [ 0.99715763 -0.16742194 -0.81356543 -0.6802668  -0.9999393 ]\n",
      " [ 0.9999983  -0.9999994  -0.9999975  -0.8594331  -0.9999881 ]\n",
      " [ 0.99928284 -0.99999803 -0.9999058   0.9857963  -0.92205757]]\n"
     ]
    }
   ],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 3\n",
    "n_neurons = 5\n",
    "\n",
    "X0 = tf.placeholder(tf.float32, [None, n_inputs])\n",
    "X1 = tf.placeholder(tf.float32, [None, n_inputs])\n",
    "\n",
    "Wx = tf.Variable(tf.random_normal(shape=[n_inputs, n_neurons], dtype=tf.float32))\n",
    "Wy = tf.Variable(tf.random_normal(shape=[n_neurons, n_neurons], dtype=tf.float32))\n",
    "b = tf.Variable(tf.zeros([1, n_neurons], dtype=tf.float32))\n",
    "\n",
    "Y0 = tf.tanh(tf.matmul(X0, Wx) + b)\n",
    "Y1 = tf.tanh(tf.matmul(Y0, Wy) + tf.matmul(X1, Wx) + b)\n",
    "\n",
    "# input data (mini-batch)\n",
    "# t = 0\n",
    "X0_batch = np.array([[0, 1, 2],  # sample 0\n",
    "                     [3, 4, 5],  # sample 1\n",
    "                     [6, 7, 8],  # sample 2\n",
    "                     [9, 0, 1]]) # sample 3\n",
    "# t = 1\n",
    "X1_batch = np.array([[9, 8, 7], \n",
    "                     [3, 4, 5], \n",
    "                     [6, 5, 4], \n",
    "                     [3, 2, 1]])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    Y0_val, Y1_val = sess.run([Y0, Y1], feed_dict={X0: X0_batch, X1: X1_batch})\n",
    "    \n",
    "print('Y0_val:{}\\n{}'.format(Y0_val.shape, Y0_val))  # shape: (4, 5) → (샘플 개수, 뉴런 개수)\n",
    "print('Y1_val:{}\\n{}'.format(Y1_val.shape, Y1_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 예제는 2개의 타임 스텝에 대해서만 RNN 연산을 수행했기 때문에 간단해 보였다. 하지만, 타임 스텝이 많아 질수록 연산 그래프가 커지게 된다. \n",
    "\n",
    "이번에는 텐서플로에서 제공하는 RNN연산을 사용해 위와 동일한 모델을 만들어 보도록 하자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 👊14.2.1 정적으로 타임 스텝 펼치기\n",
    "\n",
    "텐서플로에서 제공하는 RNN 중 [`tf.nn.rnn_cell.BasicRNNCell`](https://www.tensorflow.org/api_docs/python/tf/nn/rnn_cell/BasicRNNCell) 은 아래의 그림을 그대로 코드로 구현한 것이라고 할 수 있다.\n",
    "\n",
    "![rnn_cel](./images/rnn06.png)\n",
    "\n",
    "그런 다음 [`tf.nn.static_rnn()`](https://www.tensorflow.org/api_docs/python/tf/nn/static_rnn) 함수를 호출한 뒤 셀(`BasicRNNCell`)과 입력 텐서, 그리고 입력의 데이터 타입을 알려준다. 기본적으로 모두 $0$으로 채워진 초기 상태의 행렬을 만든다.  `static_rnn()`함수는 셀의 `__call__()`함수를 호출하여 타임 스텝마다(위의 예제에서는 2개) 셀 복사본을 만들고 서로 연결해준다. 즉, 아래의 그림처럼 하나의 RNN 셀을 타임 스텝별로 펼친 것이라 할 수 있다.\n",
    "\n",
    "\n",
    "\n",
    "![](./images/rnn07.png)\n",
    "\n",
    "\n",
    "\n",
    "`static_rnn()` 함수는 출력(output)과 상태(state)를 리턴하는데, 출력은 각 타임 스텝에서의 출력 텐서를 담고 있는 리스트(list)이고 상태는 네트워크의 최종 상태가 담겨있는 텐서이다.  따라서, 최종 상태(state)가 마지막 출력(output)과 동일하다.\n",
    "\n",
    "아래의 코드는 `BasicRNNCell`과 `static_rnn()`을 이용해 위의 예제를 똑같이 구현한 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 하나의 placeholder로 타임 스텝별 데이터 넣어주기\n",
    "\n",
    "위의 예제에서는 타임 스텝(위의 예제에서는 2개)별 플레이스홀더(placeholder) `X0, X1`를 각각 만들어 주고, 2개의 출력 텐서(tensor) `Y0, Y1`를 정의해줬다. 위의 예제에서는 2개의 타임 스텝이어서 괜찮았지만, 만약 타임 스텝이 많아 질수록 타임 스텝별로 플레이스홀더와 출력 텐서를 정의해야하기 때문에 매우 불편하다. 이러한 문제를 해결하기 위해 [미니배치, 타임스텝, 입력크기] 형태인 `[None, n_steps, n_inputs]` 하나의 플레이스홀더 `X`를 만들어 주고, 이것을 `tf.unstack()`을 이용해 타임 스텝별로 나누어 준다. 그리고 출력 `outputs`에는 `tf.stack()`을 이용해 모든 출력 텐서들을 하나의 텐서로 합친다. 아래의 예제는 위의 예제를 하나의 플레이스홀더와 출력으로 만든 예제이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-5-405ae9bdfabb>:10: BasicRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.SimpleRNNCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-5-405ae9bdfabb>:11: static_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell, unroll=True)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From C:\\Users\\heon1\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\heon1\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\rnn_cell_impl.py:459: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:Entity <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x000001A6D97786C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x000001A6D97786C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x000001A6D97786C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x000001A6D97786C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x000001A6D97786C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x000001A6D97786C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x000001A6D97786C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x000001A6D97786C8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "outputs_val:(4, 2, 5)\n",
      "[[[-0.45652324 -0.68064123  0.40938237  0.63104504 -0.45732826]\n",
      "  [-0.9428799  -0.9998869   0.94055814  0.9999985  -0.9999999 ]]\n",
      "\n",
      " [[-0.8001535  -0.9921827   0.7817797   0.9971031  -0.9964609 ]\n",
      "  [-0.95196605 -0.9902005   0.93691176  0.99884737 -0.9992145 ]]\n",
      "\n",
      " [[-0.93605185 -0.9998379   0.9308867   0.9999815  -0.99998295]\n",
      "  [-0.9165386  -0.9945604   0.896054    0.99987185 -0.9999751 ]]\n",
      "\n",
      " [[ 0.9927369  -0.9981933  -0.55543643  0.9989031  -0.9953323 ]\n",
      "  [-0.02746338 -0.73191977  0.7827872   0.9525682  -0.9781773 ]]]\n"
     ]
    }
   ],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_steps = 2  # time steps\n",
    "n_inputs = 3  # input size\n",
    "n_neurons = 5  \n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "X_seqs = tf.unstack(tf.transpose(X, perm=[1, 0, 2])) #transpose -> [n_steps, none, n_inputs]\n",
    "                                                     #unstack -> [4,3]/ [4,3] 위의 X0, X1 만들어죽\n",
    "basic_cell = tf.nn.rnn_cell.BasicRNNCell(num_units=n_neurons)\n",
    "output_seqs, states = tf.nn.static_rnn(basic_cell, X_seqs, dtype=tf.float32)\n",
    "outputs = tf.transpose(tf.stack(output_seqs), perm=[1, 0, 2])\n",
    "\n",
    "# input data\n",
    "X_batch = np.array([\n",
    "        # t = 0      t = 1 \n",
    "        [[0, 1, 2], [9, 8, 7]], # 샘플 1\n",
    "        [[3, 4, 5], [3, 4, 5]], # 샘플 2\n",
    "        [[6, 7, 8], [6, 5, 4]], # 샘플 3\n",
    "        [[9, 0, 1], [3, 2, 1]], # 샘플 4\n",
    "])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    outputs_val = outputs.eval(feed_dict={X: X_batch})\n",
    "    \n",
    "print('outputs_val:{}\\n{}'.format(outputs_val.shape, outputs_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.ops.rnn_cell_impl.BasicRNNCell at 0x1a6d97786c8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_cell #이는 기존의 앞서 배운 RNN의 틀을 잡아주는 것과 유사하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'rnn/basic_rnn_cell/Tanh_1:0' shape=(?, 5) dtype=float32>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states #state는 hiddenstate의 마지막 타임 스탭의 상태를 나타낸다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'rnn/basic_rnn_cell/Tanh:0' shape=(?, 5) dtype=float32>,\n",
       " <tf.Tensor 'rnn/basic_rnn_cell/Tanh_1:0' shape=(?, 5) dtype=float32>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_seqs #output_seqs는 각 타임 스탭의 output을 보여준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'transpose_4:0' shape=(?, 2, 5) dtype=float32>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = tf.transpose(tf.stack(output_seqs), perm=[1, 0, 2])\n",
    "outputs # 처음에 unstack으로 나누어준 데이터를 다시 원래상태로 합쳐주는것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### static_rnn()의 문제점\n",
    "\n",
    "`static_rnn()` 함수의 문제는 타임 스텝마다 하나의 셀을 그래프에 추가하기 때문에, 만약 타임 스텝이 많아질 경우 그래프가 매우 복잡해진다는 것이다. 쉽게 말하면, `for`문과 같이 반복문을 쓰지않고 동일한 셀을 타임 스텝별로 만드는 것이라 할 수 있다. 이럴 경우 타임 스텝이 많아서 그래프가 커지게되면 역전파(backprop)시에 메모리 부족(OOM, Out-Of-Memory)에러가 발생할 수 있다. \n",
    "\n",
    "이러한 문제를 해결할 수 있는 방법으로는 `tf.nn.dynamic_rnn()`이 있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 👊14.2.2 동적으로 타임 스텝 펼치기\n",
    "\n",
    "[`tf.nn.dynamic_rnn()`]은 효율적인데 이에 대해서 두가지 면을 본다면,\n",
    "\n",
    "앞서 문제점인 메모리 부족(OOM)을 어느정도 해결할 수 있다.\n",
    "\n",
    "또한 Stack을 통해 (`[None, n_steps, n_inputs]`)을 (`[n_steps, None, n_inputs]`)으로 바꿔주는 과정이 필요없다.\n",
    "\n",
    " 아래의 예제는 2.1에서 예제를 `dynamic_rnn()`을 이용해 작성한 코드이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs_val:(4, 2, 5)\n",
      "[[[-0.85115266  0.87358344  0.5802911   0.8954789  -0.0557505 ]\n",
      "  [-0.999996    0.99999577  0.9981815   1.          0.37679607]]\n",
      "\n",
      " [[-0.9983293   0.9992038   0.98071456  0.999985    0.25192663]\n",
      "  [-0.99971443  0.99907064  0.78239065  0.99999607 -0.668575  ]]\n",
      "\n",
      " [[-0.9999827   0.99999535  0.9992863   1.          0.5159072 ]\n",
      "  [-0.9993956   0.9984095   0.83422637  0.99999976 -0.47325212]]\n",
      "\n",
      " [[ 0.87888587  0.07356028  0.97216916  0.9998546  -0.7351168 ]\n",
      "  [-0.9134514   0.3600957   0.7624866   0.99817705  0.80142   ]]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "reset_graph()\n",
    "\n",
    "n_steps = 2\n",
    "n_inputs = 3\n",
    "n_neurons = 5\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "\n",
    "basic_cell = tf.nn.rnn_cell.BasicRNNCell(num_units=n_neurons)\n",
    "# dynamic_rnn()\n",
    "outputs, states = tf.nn.dynamic_rnn(basic_cell, X, dtype=tf.float32)\n",
    "\n",
    "# input data\n",
    "X_batch = np.array([\n",
    "        # t = 0      t = 1 \n",
    "        [[0, 1, 2], [9, 8, 7]], # 샘플 1\n",
    "        [[3, 4, 5], [3, 4, 5]], # 샘플 2\n",
    "        [[6, 7, 8], [6, 5, 4]], # 샘플 3\n",
    "        [[9, 0, 1], [3, 2, 1]], # 샘플 4\n",
    "])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    outputs_val = outputs.eval(feed_dict={X: X_batch})\n",
    "    \n",
    "print('outputs_val:{}\\n{}'.format(outputs_val.shape, outputs_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 👊14.2.3 가변 길이 입력/출력 시퀀스 다루기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.1 가변 길이 입력 시퀀스\n",
    "#### 이 부분부터는 가변적인 길이를 다루며, 방법도 다양해 참고만 할만하다..\n",
    "2.1 ~ 2.2에서는 데이터의 타임 스텝이 **고정 길이**를 가진 입력 시퀀스만 다루었다. 하지만, 만약에 입력 시퀀스의 길이가 고정이지 않고 가변 길이일 경우에는 `tf.nn.dynamic_rnn()`함수에 `sequence_length` 인자를 설정해야 한다. `sequence_length`는 각 데이터 샘플의 입력 시퀀스 길이를 1D 텐서로 지정해준다. \n",
    "\n",
    "우선, 입력 시퀀스에 대한 예제를 보자. 아래의 코드 처럼 두번째 입력 시퀀스(샘플 2)가 두 개가 아니라 하나의 입력만 있을 경우, 입력 텐서 `X`에 맞춰 주기 위해 나머지 하나를 $0$벡터 `[0, 0, 0]`으로 채워(패딩)줘야 한다. 그리고 `dynamic_rnn()`의 `sequence_length`인자에 넣어주기 위해 데이터 샘플의 길이를 `seq_length_batch`를 만들어 준다.\n",
    "\n",
    "```python\n",
    "X_batch = np.array([\n",
    "        # t = 0      t = 1 \n",
    "        [[0, 1, 2], [9, 8, 7]], # 샘플 1\n",
    "        [[3, 4, 5], [0, 0, 0]], # 샘플 2 (0 벡터로 패딩)\n",
    "        [[6, 7, 8], [6, 5, 4]], # 샘플 3\n",
    "        [[9, 0, 1], [3, 2, 1]], # 샘플 4\n",
    "])\n",
    "seq_length_batch = np.array([2, 1, 2, 2])  # 각 샘플 시퀀스 길이 \n",
    "``` \n",
    "두번째 행을 보면 뒤에 부분이 0으로 패딩되어 있다.\n",
    "\n",
    "\n",
    "아래의 예제는 위의 데이터를 가지고 2.1 ~ 2.2에서 처럼 동일한 RNN 연산을 한 코드이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs_val:(4, 2, 5)\n",
      "[[[-0.9123188   0.16516446  0.5548655  -0.39159346  0.20846416]\n",
      "  [-1.          0.956726    0.99831694  0.99970174  0.96518576]]\n",
      "\n",
      " [[-0.9998612   0.6702289   0.9723653   0.6631046   0.74457586]\n",
      "  [ 0.          0.          0.          0.          0.        ]]\n",
      "\n",
      " [[-0.99999976  0.8967997   0.9986295   0.9647514   0.93662   ]\n",
      "  [-0.9999526   0.9681953   0.96002865  0.98706263  0.85459226]]\n",
      "\n",
      " [[-0.96435434  0.99501586 -0.36150697  0.9983378   0.999497  ]\n",
      "  [-0.9613586   0.9568762   0.7132288   0.97729224 -0.0958299 ]]]\n"
     ]
    }
   ],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_steps = 2\n",
    "n_inputs = 3\n",
    "n_neurons = 5\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "seq_length = tf.placeholder(tf.int32, [None])  # 시퀀스 길이를 넣어줄 placeholder\n",
    "\n",
    "basic_cell = tf.nn.rnn_cell.BasicRNNCell(num_units=n_neurons)\n",
    "outputs, states = tf.nn.dynamic_rnn(basic_cell, X, dtype=tf.float32,\n",
    "                                    sequence_length=seq_length)\n",
    "\n",
    "# input data\n",
    "X_batch = np.array([\n",
    "        # t = 0      t = 1 \n",
    "        [[0, 1, 2], [9, 8, 7]], # 샘플 1\n",
    "        [[3, 4, 5], [0, 0, 0]], # 샘플 2 (0 벡터로 패딩)\n",
    "        [[6, 7, 8], [6, 5, 4]], # 샘플 3\n",
    "        [[9, 0, 1], [3, 2, 1]], # 샘플 4\n",
    "])\n",
    "# seq length\n",
    "seq_length_batch = np.array([2, 1, 2, 2])  # 각 샘플 시퀀스 길이\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    outputs_val, states_val = sess.run([outputs, states], \n",
    "                                       feed_dict={X: X_batch, seq_length: seq_length_batch})\n",
    "    \n",
    "print('outputs_val:{}\\n{}'.format(outputs_val.shape, outputs_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 출력 결과에서 확인할 수 있듯이 두번째 데이터(샘플2)에 대해서는 시퀀스 길이가 초과하는 타임 스텝에 대해서는 $0$ 벡터(`[0, 0, 0]`)를 출력하는 것을 알 수 있다.\n",
    "**하지만 입력이 저렇다고 출력이 꼭 0이 아닐수도 있다. 상황마다 다 다르기 때문에 참고만 하는 것이 좋다**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.2 가변 길이 출력 시퀀스 \n",
    "\n",
    "입력 시퀀스(데이터)의 길이는 우리가 확인할 수 있기 때문에 `sequence_length`인자에 지정할 수 있었다. 하지만, 출력 시퀀스는 입력 시퀀스의 길이와 같은 경우를 제외하고는 알 수가 없는데, 예를들어 기계번역과 같은 경우에는 출력의 시퀀스가 각각 다르게 나오기 때문에 정확한 출력 시퀀스의 길이를 알기 어렵다. \n",
    "\n",
    "이러한 경우에는 일반적으로 입력 시퀀스에 **EOS 토큰**(End-Of-Sequence token)을 추가하여 출력 시퀀스에서 EOS가 나왔을 때, EOS보다 뒤에 나오는 출력을 무시하는 방법을 사용한다. \n",
    "\n",
    "**입력과 출력이 모두 가변적일 경우, 입력 출력 모두 sequence보다 짧으면\n",
    "0을 패딩해주고, 너무 길면 sequence까지만 사용하는 것이 조금은 더 보편적이다.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 👊14.3. 마무리\n",
    "\n",
    "이번 포스팅에서는 시계열 데이터에 적합한 모델인 RNN의 구조와 텐서플로를 이용해 RNN을 구현하는 방법에 대해 알아보았다. \n",
    "\n",
    "다음 포스팅에서는 RNN을 학습시키는 방법과 심층 RNN에 대해 알아보도록 하자."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
